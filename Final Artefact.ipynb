{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import glob\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "import gc\n",
    "import random\n",
    "from tensorflow.keras.layers import Input, Conv3D, Conv3DTranspose, MaxPooling3D, UpSampling3D, Cropping3D, Flatten, Reshape, Dense\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "RootFolder = \"G:/File\" # Modify the Root Folder\n",
    "DataFolder = os.path.join(RootFolder, \"DataSet/Outputs/cpac/filt_global\")\n",
    "PhenoTypePos = os.path.join(RootFolder, \"DataSet/Phenotypic_V1_0b_preprocessed1.csv\")\n",
    "NewDataFolder = os.path.join(RootFolder, \"NewDataSet\")\n",
    "\n",
    "FileMapping = {'func_preproc' : '_func_preproc.nii.gz',\n",
    "               'rois_aal' : '_rois_aal.1D',\n",
    "               'rois_cc200' : '_rois_cc200.1D',\n",
    "               'rois_cc400' : '_rois_cc400.1D'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSubjectInfo(SubjectIDs, InfoName):\n",
    "    VarDict = {}\n",
    "    with open(PhenoTypePos) as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        for row in reader:\n",
    "            if row['SUB_ID'] in SubjectIDs:\n",
    "                VarDict[row['SUB_ID']] = row[InfoName]\n",
    "    return VarDict\n",
    "\n",
    "def GetASDLabels(SubjectIDs):\n",
    "    DXDict = GetSubjectInfo(SubjectIDs, 'DX_GROUP')\n",
    "    Labels = np.zeros(len(SubjectIDs))\n",
    "    for i in range(len(SubjectIDs)):\n",
    "        Labels[i] =  DXDict[SubjectIDs[i]]\n",
    "    for i in range(len(Labels)):\n",
    "        if Labels[i] > 0:\n",
    "            Labels[i] = Labels[i] - 1\n",
    "    return Labels\n",
    "\n",
    "def GetASDSite(SubjectIDs):\n",
    "    SiteId = GetSubjectInfo(SubjectIDs, 'SITE_ID')\n",
    "    SiteAll = []\n",
    "    for i in range(len(SubjectIDs)):\n",
    "        SiteAll.append(SiteId[SubjectIDs[i]])\n",
    "    return np.array(SiteAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CaculatingCorr(A, B):\n",
    "    # print(A.shape, \" \", B.shape)\n",
    "    A_mA = A - A.mean(1)[:, None]\n",
    "    B_mB = B - B.mean(1)[:, None]\n",
    "\n",
    "    ssA = (A_mA**2).sum(1)\n",
    "    ssB = (B_mB**2).sum(1)\n",
    "    # print(ssA[:, None].shape, \" \", ssB[None].shape)\n",
    "    div = np.dot(ssA[:, None], ssB[None])\n",
    "    # print(div.shape)\n",
    "    div[div == 0.] = 1\n",
    "\n",
    "    Output = np.dot(A_mA, B_mB.T) / np.sqrt(div)\n",
    "\n",
    "    return Output\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list = tf.train.BytesList(value = [value]))\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list = tf.train.FloatList(value = [value]))\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list = tf.train.Int64List(value = [value]))\n",
    "\n",
    "def StoreCorrelation(ID, SubjectID, Size, Img, Type):\n",
    "    SavePos = '/File/NewDataSet/Correlation/' + Type\n",
    "    # print(SavePos)\n",
    "    if not os.path.exists(SavePos):\n",
    "        os.mkdir(SavePos)\n",
    "    SaveFile = os.path.join(SavePos, SubjectID + '.tfrecords')\n",
    "    if not os.path.exists(SaveFile):\n",
    "        os.chdir(os.path.join(DataFolder, Type))\n",
    "        RoisPos = glob.glob(\"*\" + SubjectID + FileMapping[Type])[0]\n",
    "        Rois = np.loadtxt(RoisPos, skiprows = 0)\n",
    "        Corr = np.float32(CaculatingCorr(Img.reshape(-1, Img.shape[3]), Rois.T))\n",
    "        Corr[np.isnan(Corr)] = 0.\n",
    "\n",
    "        features = {}\n",
    "        writer = tf.io.TFRecordWriter(SaveFile)\n",
    "        feature = {\n",
    "            \"array\" : _bytes_feature(tf.io.serialize_tensor(Corr.reshape(Size)).numpy()),\n",
    "            \"label\" : _float_feature(Labels[ID])\n",
    "        }\n",
    "        tf_example = tf.train.Example(features = tf.train.Features(feature = feature))\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "        # Haha = tf.io.parse_single_example(example.SerializeToString(), feature_decode)\n",
    "        # data = tf.io.decode_raw(Haha['AAL'], out_type = tf.float32)\n",
    "        # size = Haha['shape']\n",
    "        writer.close()\n",
    "    # print('Finishing ' + Type)\n",
    "\n",
    "def CreateCorrelation(SubjectIDs, Labels):\n",
    "    for i in range(len(SubjectIDs)):\n",
    "        id = SubjectIDs[i]\n",
    "        \n",
    "        SavePos = os.path.join(os.path.join(NewDataFolder, \"Correlation\"))\n",
    "        print(\"Searching Data\", id)\n",
    "        if not os.path.exists(SavePos):\n",
    "            os.mkdir(SavePos)\n",
    "\n",
    "        os.chdir(os.path.join(DataFolder, \"func_preproc\"))\n",
    "        SubjectPos = glob.glob(\"*\" + id + FileMapping['func_preproc'])[0]\n",
    "        Subject = nib.load(SubjectPos)\n",
    "        Img = Subject.get_fdata()\n",
    "        \n",
    "        StoreCorrelation(i, id, [61, 73, 61, 116], Img, 'rois_aal')\n",
    "        # StoreCorrelation(i, id, [61, 73, 61, 200], Img, 'rois_cc200')\n",
    "        # StoreCorrelation(i, id, [61, 73, 61, 392], Img, 'rois_cc400')\n",
    "\n",
    "decode_description = {\n",
    "    \"array\" : tf.io.FixedLenFeature([], tf.string),\n",
    "    \"label\" : tf.io.FixedLenFeature([], tf.float32)\n",
    "}\n",
    "\n",
    "def decode_function(example_proto):\n",
    "    features = tf.io.parse_single_example(example_proto, decode_description)\n",
    "    features[\"array\"] = tf.io.parse_tensor(features[\"array\"], \"float32\")\n",
    "    features[\"label\"] = features[\"label\"].numpy()\n",
    "    return features\n",
    "\n",
    "def ReadFile(IdList, Type):\n",
    "    # print(IdList)\n",
    "    os.chdir(os.path.join(os.path.join(NewDataFolder, \"Correlation\"), Type))\n",
    "    Raw = tf.data.TFRecordDataset(IdList)\n",
    "    X = []\n",
    "    Y = []\n",
    "    for features in Raw:\n",
    "        Transfer = decode_function(features)\n",
    "        X.append(Transfer['array'])\n",
    "        Y.append(Transfer['label'])\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    return X, Y\n",
    "\n",
    "# TrainId = os.path.join(RootFolder, \"DataSet/ABIDEI.txt\")\n",
    "# SubjectIDs = np.genfromtxt(TrainId, dtype=str)\n",
    "# Labels = GetASDLabels(SubjectIDs)\n",
    "# CreateCorrelation(SubjectIDs, Labels)\n",
    "\n",
    "# X, Y = ReadFile(['50004.tfrecords', '50009.tfrecords'], 'rois_cc200')\n",
    "# print(X.shape)\n",
    "# print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884\n"
     ]
    }
   ],
   "source": [
    "TrainId = os.path.join(RootFolder, \"DataSet/ABIDEI.txt\")\n",
    "SubjectIDs = np.genfromtxt(TrainId, dtype=str)\n",
    "print(len(SubjectIDs))\n",
    "A = random.sample(list(SubjectIDs), len(SubjectIDs) // 5)\n",
    "A.sort()\n",
    "File = open(os.path.join(RootFolder, \"DataSet/ABIDEII.txt\"), mode = \"w\")\n",
    "for item in A:\n",
    "    File.write(item + '\\n')\n",
    "File.close()\n",
    "# np.savetxt(os.path.join(RootFolder, \"DataSet/ABIDEII.txt\"), A)\n",
    "# \n",
    "# File.write(str(A))\n",
    "# File.close()\n",
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<keras.engine.functional.Functional at 0x22abeac2910>,\n",
       " <keras.engine.functional.Functional at 0x22abeacfb80>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def AutoEncoderModel(input_size):\n",
    "    N = input_size[3]\n",
    "    origin = Input(shape = input_size)\n",
    "    x = Conv3D(16, (3, 3, 3), activation = 'relu', padding = 'same')(origin)\n",
    "    x = MaxPooling3D((2, 2, 2), padding = 'same')(x)\n",
    "    x = Conv3D(8, (3, 3, 3), activation = 'relu', padding = 'same')(x)\n",
    "    x = MaxPooling3D((2, 2, 2), padding = 'same')(x)\n",
    "    x = Conv3D(4, (3, 3, 3), activation = 'relu', padding = 'same')(x)\n",
    "    x = MaxPooling3D((2, 2, 2), padding = 'same')(x)\n",
    "    x = Flatten()(x)\n",
    "    encoded = Dense(64, activation = 'relu')(x)\n",
    "\n",
    "    x = Dense(8 * 10 * 8 * 4, activation = 'relu')(encoded)\n",
    "    x = Reshape([8, 10, 8, 4])(x)\n",
    "    x = Conv3D(4, (3, 3, 3), activation = 'relu', padding = 'same')(x)\n",
    "    x = UpSampling3D((2, 2, 2))(x)\n",
    "    x = Conv3D(8, (3, 3, 3), activation = 'relu', padding = 'same')(x)\n",
    "    x = UpSampling3D((2, 2, 2))(x)\n",
    "    x = Conv3D(16, (3, 3, 3), activation = 'relu', padding = 'same')(x)\n",
    "    x = UpSampling3D((2, 2, 2))(x)\n",
    "    x = Conv3D(N, (3, 3, 3), activation = 'relu', padding = 'same')(x)\n",
    "    decoded = Cropping3D(((3, 0), (7, 0), (3, 0)))(x)\n",
    "\n",
    "    autoencoder = Model(origin, decoded)\n",
    "    encoder = Model(origin, encoded)\n",
    "    # autoencoder.summary()\n",
    "    return encoder, autoencoder\n",
    "\n",
    "AutoEncoderModel((61, 73, 61, 116))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator(SubjectIDs, Id, batchsz):\n",
    "    random.shuffle(Id)\n",
    "    NumOfBatch = (len(Id) // batchsz) + (len(Id) % batchsz != 0)\n",
    "    # print(NumOfBatch, len(TrainId), batchsz)\n",
    "    n = 1\n",
    "    # print(\"Here\")\n",
    "    while 1:\n",
    "        Ids = []\n",
    "        X = []\n",
    "        Y = []\n",
    "        if n > NumOfBatch:\n",
    "            n = 1\n",
    "        if n == NumOfBatch:\n",
    "            for i in range((n - 1) * batchsz, len(Id)):\n",
    "                Ids.append(str(SubjectIDs[Id[i]]) + '.tfrecords')\n",
    "            X, Y = ReadFile(IdList = Ids, Type = 'rois_aal')\n",
    "        else:\n",
    "            for i in range((n - 1) * batchsz, n * batchsz):\n",
    "                Ids.append(str(SubjectIDs[Id[i]]) + '.tfrecords')\n",
    "            X, Y = ReadFile(IdList = Ids, Type = 'rois_aal')\n",
    "        n = n + 1\n",
    "        gc.collect()\n",
    "        yield X, X\n",
    "\n",
    "# def TrainAndEvaluate(SubjectIDs, TrainId, TestId, params):\n",
    "#     batchsz = params['batch_size']\n",
    "#     modelE, modelAE = AutoEncoderModel((61, 73, 61, 116))\n",
    "#     modelAE.compile(optimizer = 'adam', loss = 'mse', metrics = ['accuracy'])\n",
    "#     Ids = []\n",
    "#     for i in range(len(TrainId)):\n",
    "#         Ids.append(str(SubjectIDs[TrainId[i]]) + '/aal.tfrecords')\n",
    "#     TrainX, TrainY = ReadFile(IdList = Ids)\n",
    "#     history = modelAE.fit(TrainX, TrainX, epochs = params['epochs'], batch_size = batchsz, verbose = 1, validation_split = 0.2)\n",
    "#     Ids = []\n",
    "#     for i in range(len(TestId)):\n",
    "#         Ids.append(str(SubjectIDs[TestId[i]]) + '/aal.tfrecords')\n",
    "#     TestX, TestY = ReadFile(IdList = Ids)\n",
    "#     loss, accuracy = modelAE.evaluate(TestX, TestX)\n",
    "#     return loss, history, modelE\n",
    "\n",
    "def TrainAndEvaluate(SubjectIDs, TrainId, TestId, params):\n",
    "    batchsz = params['batch_size']\n",
    "    modelE, modelAE = AutoEncoderModel((61, 73, 61, 116))\n",
    "    modelE.compile(optimizer = 'adam', loss = 'mse')\n",
    "    modelAE.compile(optimizer = 'adam', loss = 'mse')\n",
    "\n",
    "    history = modelAE.fit(Generator(SubjectIDs, TrainId, batchsz), steps_per_epoch = (len(TrainId) // batchsz), epochs = params['epochs'], verbose = 1)\n",
    "\n",
    "    scores = modelAE.evaluate(Generator(SubjectIDs, TestId, batchsz), steps = (len(TestId) // batchsz))\n",
    "\n",
    "    return scores, modelE\n",
    "\n",
    "def AutoEncoderResult(SubjectIDs, params):\n",
    "    Loss = []\n",
    "    for i, (train, test) in enumerate(params['skf']):\n",
    "        print('Start Train ' + str(i + 1) + ' Fold')\n",
    "        gc.collect()\n",
    "        loss, history, modelE = TrainAndEvaluate(SubjectIDs, train, test, params)\n",
    "        Loss.append(loss)\n",
    "    return Loss\n",
    "\n",
    "def GetAEModel(SubjectIDs, params):\n",
    "    train, test = params['skf']\n",
    "    scores, modelE = TrainAndEvaluate(SubjectIDs, train, test, params)\n",
    "    return scores, modelE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "35/35 [==============================] - 201s 5s/step - loss: 0.0087\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 186s 5s/step - loss: 0.0087\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 186s 5s/step - loss: 0.0085\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 187s 5s/step - loss: 0.0085\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 187s 5s/step - loss: 0.0085\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 189s 5s/step - loss: 0.0083\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 189s 5s/step - loss: 0.0084\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 189s 5s/step - loss: 0.0084\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 192s 5s/step - loss: 0.0083\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 190s 5s/step - loss: 0.0083\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 188s 5s/step - loss: 0.0083\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 188s 5s/step - loss: 0.0082\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 189s 5s/step - loss: 0.0083\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 188s 5s/step - loss: 0.0083\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 193s 6s/step - loss: 0.0082\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 190s 5s/step - loss: 0.0081\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 189s 5s/step - loss: 0.0081\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 189s 5s/step - loss: 0.0082\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 189s 5s/step - loss: 0.0082\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 189s 5s/step - loss: 0.0081\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 188s 5s/step - loss: 0.0082\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 189s 5s/step - loss: 0.0081\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 188s 5s/step - loss: 0.0082\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 191s 5s/step - loss: 0.0081\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 188s 5s/step - loss: 0.0082\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 190s 5s/step - loss: 0.0082\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 188s 5s/step - loss: 0.0081\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 189s 5s/step - loss: 0.0081\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 188s 5s/step - loss: 0.0081\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 189s 5s/step - loss: 0.0081\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 188s 5s/step - loss: 0.0081\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 188s 5s/step - loss: 0.0082\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 189s 5s/step - loss: 0.0081\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 192s 5s/step - loss: 0.0082\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 189s 5s/step - loss: 0.0081\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 189s 5s/step - loss: 0.0082\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 194s 6s/step - loss: 0.0082\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 188s 5s/step - loss: 0.0082\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 188s 5s/step - loss: 0.0081\n",
      "Epoch 40/50\n",
      "35/35 [==============================] - 189s 5s/step - loss: 0.0082\n",
      "Epoch 41/50\n",
      "35/35 [==============================] - 190s 5s/step - loss: 0.0082\n",
      "Epoch 42/50\n",
      "35/35 [==============================] - 188s 5s/step - loss: 0.0081\n",
      "Epoch 43/50\n",
      "35/35 [==============================] - 189s 5s/step - loss: 0.0082\n",
      "Epoch 44/50\n",
      "35/35 [==============================] - 189s 5s/step - loss: 0.0082\n",
      "Epoch 45/50\n",
      "35/35 [==============================] - 190s 5s/step - loss: 0.0081\n",
      "Epoch 46/50\n",
      "35/35 [==============================] - 189s 5s/step - loss: 0.0081\n",
      "Epoch 47/50\n",
      "35/35 [==============================] - 189s 5s/step - loss: 0.0081\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - 189s 5s/step - loss: 0.0081\n",
      "Epoch 49/50\n",
      "35/35 [==============================] - 188s 5s/step - loss: 0.0082\n",
      "Epoch 50/50\n",
      "35/35 [==============================] - 190s 5s/step - loss: 0.0081\n",
      "8/8 [==============================] - 41s 6s/step - loss: 0.0085\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description = 'Autoencoder')\n",
    "parser.add_argument('-l', default = 0.001, type = float, help = 'Learning rate')\n",
    "parser.add_argument('-e', default = 50, type = int, help = 'epochs')\n",
    "parser.add_argument('-b', default = 4, type = int, help = 'batch_size')\n",
    "parser.add_argument('-g', default = 1, type = int, help = 'Number of GPUs to use during the training')\n",
    "args = parser.parse_args(args = [])\n",
    "params = dict()\n",
    "params['lrate'] = args.l\n",
    "params['epochs'] = args.e\n",
    "params['batch_size'] = args.b\n",
    "params['gpu_count'] = args.g\n",
    "\n",
    "TrainPos = os.path.join(RootFolder, \"DataSet/ABIDEII.txt\")\n",
    "SubjectIDs = np.genfromtxt(TrainPos, dtype=str)\n",
    "Labels = GetASDLabels(SubjectIDs)\n",
    "TestX = random.sample(range(0, len(SubjectIDs)), len(SubjectIDs) // 5)\n",
    "TrainX = list(np.array([i for i in range(len(SubjectIDs)) if i not in TestX]))\n",
    "# print(TestX)\n",
    "# print(TrainX)\n",
    "params['skf'] = (TrainX, TestX)\n",
    "scores, modelE = GetAEModel(SubjectIDs, params)\n",
    "# Site = GetASDSite(SubjectIDs)\n",
    "# skf = KFold(n_splits = 10, shuffle = True).split(Site)\n",
    "# params['skf'] = skf\n",
    "# history = AutoEncoderResult(SubjectIDs, params)\n",
    "# CreateCorrelation(SubjectIDs, Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = modelE.get_weights()\n",
    "# print(A)\n",
    "modelE.save(os.path.join(RootFolder, 'my_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(884, 64)\n",
      "(884, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "TrainPos = os.path.join(RootFolder, \"DataSet/ABIDEI.txt\")\n",
    "SubjectIDs = np.genfromtxt(TrainPos, dtype=str)\n",
    "Labels = GetASDLabels(SubjectIDs)\n",
    "feature = []\n",
    "target = []\n",
    "modelE = load_model(os.path.join(RootFolder, 'my_model.h5'))\n",
    "for i in range(len(SubjectIDs)):\n",
    "    Ids = [str(SubjectIDs[i]) + '.tfrecords']\n",
    "    # print(Ids)\n",
    "    X, Y = ReadFile(IdList = Ids, Type = 'rois_aal')\n",
    "    X = modelE.predict(X)\n",
    "    feature.append(X.reshape([64]))\n",
    "    target.append(Y)\n",
    "print(np.array(feature).shape)\n",
    "print(np.array(target).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = np.array(feature)\n",
    "target = np.array(target).reshape(len(target))\n",
    "np.savez(os.path.join(RootFolder, \"final.npz\"), x = feature, y = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6251768033946252\n",
      "0.5536723163841808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "data = np.load(os.path.join(RootFolder, \"final.npz\"))\n",
    "x_train, x_test, y_train, y_test = train_test_split(data['x'], data['y'], test_size=0.2)\n",
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "knn.fit(x_train, y_train)\n",
    "print(knn.score(x_train, y_train))\n",
    "print(knn.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5912305516265912\n",
      "0.6214689265536724\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "data = np.load(os.path.join(RootFolder, \"final.npz\"))\n",
    "x_train, x_test, y_train, y_test = train_test_split(data['x'], data['y'], test_size=0.2)\n",
    "clf = svm.SVC(C = 0.5, kernel = 'rbf', gamma = 1, decision_function_shape = 'ovr')\n",
    "clf.fit(x_train, y_train)\n",
    "print(clf.score(x_train, y_train))\n",
    "print(clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 14ms/step - loss: 0.6953 - accuracy: 0.5205\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6936 - accuracy: 0.5431\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.6858 - accuracy: 0.5629\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6810 - accuracy: 0.5587\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.6762 - accuracy: 0.5672\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6759 - accuracy: 0.5644\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6803 - accuracy: 0.5446\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6744 - accuracy: 0.5601\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6651 - accuracy: 0.5926\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.6617 - accuracy: 0.5856\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.6522 - accuracy: 0.5969\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6430 - accuracy: 0.6209\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6430 - accuracy: 0.6238\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6430 - accuracy: 0.6223\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6406 - accuracy: 0.6082\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6304 - accuracy: 0.6478\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6205 - accuracy: 0.6407\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6146 - accuracy: 0.6577\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.5919 - accuracy: 0.6690\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6345 - accuracy: 0.6421\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5964 - accuracy: 0.6846\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.6003 - accuracy: 0.6634\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5782 - accuracy: 0.6931\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5656 - accuracy: 0.6945\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5778 - accuracy: 0.6888\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5268 - accuracy: 0.7369\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5251 - accuracy: 0.7171\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5093 - accuracy: 0.7525\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5096 - accuracy: 0.7383\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4959 - accuracy: 0.7482\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5492 - accuracy: 0.6733\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5055 - accuracy: 0.7468\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7822\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4853 - accuracy: 0.7454\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4551 - accuracy: 0.7680\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4505 - accuracy: 0.7737\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4224 - accuracy: 0.7907\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.7977\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4077 - accuracy: 0.8147\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.8274\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3680 - accuracy: 0.8416\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3650 - accuracy: 0.8345\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3478 - accuracy: 0.8416\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3418 - accuracy: 0.8543\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3266 - accuracy: 0.8557\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8246\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3151 - accuracy: 0.8755\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3072 - accuracy: 0.8755\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2921 - accuracy: 0.8812\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3155 - accuracy: 0.8614\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2923 - accuracy: 0.8798\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2610 - accuracy: 0.9038\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2377 - accuracy: 0.9010\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2244 - accuracy: 0.9123\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2301 - accuracy: 0.9081\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2213 - accuracy: 0.9180\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2147 - accuracy: 0.9180\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2443 - accuracy: 0.8953\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2474 - accuracy: 0.9010\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2318 - accuracy: 0.8982\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1844 - accuracy: 0.9378\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1759 - accuracy: 0.9448\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1641 - accuracy: 0.9477\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1454 - accuracy: 0.9477\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1424 - accuracy: 0.9533\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1244 - accuracy: 0.9661\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1247 - accuracy: 0.9646\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1208 - accuracy: 0.9618\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1226 - accuracy: 0.9632\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1166 - accuracy: 0.9562\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1420 - accuracy: 0.9463\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1547 - accuracy: 0.9392\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1518 - accuracy: 0.9477\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1342 - accuracy: 0.9533\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1316 - accuracy: 0.9491\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1588 - accuracy: 0.9378\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1330 - accuracy: 0.9519\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.9689\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0860 - accuracy: 0.9774\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0659 - accuracy: 0.9873\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0600 - accuracy: 0.9887\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2301 - accuracy: 0.9180\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1647 - accuracy: 0.9364\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1583 - accuracy: 0.9378\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1439 - accuracy: 0.9533\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1094 - accuracy: 0.9703\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0926 - accuracy: 0.9703\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0590 - accuracy: 0.9929\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0496 - accuracy: 0.9943\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0508 - accuracy: 0.9901\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0656 - accuracy: 0.9830\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0613 - accuracy: 0.9873\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0537 - accuracy: 0.9929\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0493 - accuracy: 0.9943\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0354 - accuracy: 0.9986\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0263 - accuracy: 0.9986\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0333 - accuracy: 0.9972\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 3.1727 - accuracy: 0.5141\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "data = np.load(os.path.join(RootFolder, \"final.npz\"))\n",
    "x_train, x_test, y_train, y_test = train_test_split(data['x'], data['y'], test_size=0.2)\n",
    "y_train.reshape((-1, 1))\n",
    "# print(y_train.shape)\n",
    "# print(y_train)\n",
    "def Models(input_size):\n",
    "    origin = Input(shape = input_size)\n",
    "    x = Dense(1000, activation = 'relu')(origin)\n",
    "    x = Dense(500, activation = 'relu')(x)\n",
    "    result = Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "    model = Model(origin, result)\n",
    "    # autoencoder.summary()\n",
    "    return model\n",
    "\n",
    "model = Models(64)\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(x_train, y_train, epochs = 100, verbose = 1)\n",
    "scores = model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('DPLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81867e46d0055bf339be014e1448fa33a931f06a3c0be50f6d883dd718472d42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
